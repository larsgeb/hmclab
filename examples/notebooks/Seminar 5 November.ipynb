{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'hmc_tomography'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-74c69cd3d249>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhmc_tomography\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhmc_tomography\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSamplers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhmc_tomography\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhmc_tomography\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVisualization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'hmc_tomography'"
     ]
    }
   ],
   "source": [
    "from hmc_tomography import Distributions\n",
    "from hmc_tomography import Samplers\n",
    "from hmc_tomography import Samples\n",
    "from hmc_tomography import Visualization\n",
    "\n",
    "# Our trusty imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1: Starting simple, sampling the standard normal distribution\n",
    "\n",
    "First we create an instance of this distribution. This allows us to compute misfits and gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_simple_distribution = Distributions.StandardNormal1D()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we create a sampler and set the important parameters.\n",
    "\n",
    "**Try finding these s.t. the acceptance rate is about 0.63!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: Warning: \r\n",
      "Silently overwriting samples file (samples_simple_distribution.h5) if it exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5753d34fdd345f894405532d212d929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Sampling. Acceptance rate:'), FloatProgress(value=0.0, layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Change things here ----------------------------------------------------------------------------<<<\n",
    "# Pick a sampler from the submodule, and instantiate it. Try out with RWMH too!\n",
    "sampler = Samplers.HMC()\n",
    "# Don't sample too long, don't sample too short\n",
    "proposals = 1000\n",
    "# Ideal acceptance rate is 0.63 (HMC) for Gaussians, find a stepsize that does this.\n",
    "stepsize = 0.5\n",
    "# ----------------------------------------------------------------------------------------\n",
    "\n",
    "# Start sampling\n",
    "sampler.sample(\n",
    "    \"samples_simple_distribution.h5\",\n",
    "    a_simple_distribution,\n",
    "    proposals=proposals,\n",
    "    stepsize=stepsize,\n",
    "    overwrite_existing_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's look at the results:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\"samples_simple_distribution.h5\") as samples:\n",
    "    print(\"Samples object content:\", samples.numpy)\n",
    "    print(f\"\\r\\nWith shape: {samples.numpy.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, this thing contains all the samples `[0,:]` and all the misfits `[1,:]`.\n",
    "\n",
    "**Let's visualize them:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\"samples_simple_distribution.h5\") as samples:\n",
    "\n",
    "    # FILL IN HERE ------------------------------------------------------------------------------<<<\n",
    "    parameter_0 = None  # how can you extract the values from samples?\n",
    "    misfit = None  # How can you extract the misfits from samples?\n",
    "    # ---------------------------------------------------------------------\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(parameter_0, color=\"k\", label=\"parameter 0\")\n",
    "    plt.xlabel(\"sample index\")\n",
    "    plt.ylabel(\"parameter value\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.semilogy(misfit, \"r\")\n",
    "    plt.xlabel(\"sample index\")\n",
    "    plt.ylabel(\"misfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A lot of the time, histograms are much easier to read:**\n",
    "\n",
    "Try changing the bins value to see the effect on the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(2, 1, 1)\n",
    "plt.hist(parameter_0, label=\"parameter 0\", color=\"k\", bins=25, density=True)\n",
    "plt.xlabel(\"parameter value\")\n",
    "plt.ylabel(\"density\")\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.hist(misfit, color=\"r\", bins=25)  # Change this guy! bins=5, bins=100! ----------------------<<<\n",
    "plt.xlabel(\"misfit\")\n",
    "plt.ylabel(\"count\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's compare the sampling result to the exact answer:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_0 = np.linspace(-3, 3, 1000)\n",
    "misfit_exact = np.exp(-0.5 * (par_0 ** 2)) / (np.pi * 2) ** 0.5\n",
    "plt.plot(par_0, misfit_exact, label=\"True probability\")\n",
    "plt.xlabel(\"parameter value\")\n",
    "plt.hist(\n",
    "    parameter_0, label=\"parameter 0 sampling results\", color=\"k\", bins=25, density=True\n",
    ")\n",
    "plt.xlabel(\"parameter value\")\n",
    "plt.ylabel(\"density\")\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All this plotting stuff becomes boring quick, so here's an easy function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\"samples_simple_distribution.h5\") as samples:\n",
    "    Visualization.marginal(samples, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2: Small upgrade, sampling a non-linear distribution\n",
    "\n",
    "Here we sample a 1-dimensional Laplace distribution, which I have artificially bounded at -0.25:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.array([[1.5]])\n",
    "disperion = np.array([[0.75]])\n",
    "lower_bound = np.array([[-0.25]])\n",
    "\n",
    "a_more_complicated_distribution = Distributions.Laplace(\n",
    "    mean, disperion, lower_bounds=lower_bound\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Changing the stepsize becomes really boring. Below, you can try enabling _autotuning_. WOW!** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sys:1: Warning: \r\n",
      "Silently overwriting samples file (a_more_complicated_distribution.h5) if it exists.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6daec98113d4e4da93bcedddf29b796",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Sampling. Acceptance rate:'), FloatProgress(value=0.0, layout=Layout(flex='2'), maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sampler = Samplers.HMC()\n",
    "\n",
    "proposals = 25000\n",
    "stepsize = 0.75e2\n",
    "\n",
    "\n",
    "sampler.sample(\n",
    "    \"a_more_complicated_distribution.h5\",\n",
    "    a_more_complicated_distribution,\n",
    "    proposals=proposals,\n",
    "    stepsize=stepsize,\n",
    "    autotuning=True,  # Try enabling this. ----------------------------------------------------------<<<\n",
    "    overwrite_existing_file=True,\n",
    "    learning_rate=0.51,  # Only change this if you're bored.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the stepsizes is always a good idea to see if we will need any burn-in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7eff8f849950>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampler.plot_stepsizes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our marginal now. \n",
    "\n",
    "**If you think the marginal is incorrent, try visualizing it while accounting for burn in. ðŸ”¥ðŸ”¥** E.g. try discarding the first 1000 samples by setting burn in equal to that number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\n",
    "    \"a_more_complicated_distribution.h5\", burn_in=0  # Check this line for burn-in ------------------<<<\n",
    ") as samples:\n",
    "    Visualization.marginal(samples, 0, bins=50)\n",
    "\n",
    "    plt.plot(samples.misfits, \"r\")\n",
    "    plt.xlabel(\"sample index\")\n",
    "    plt.ylabel(\"misfit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3: The ultimate test for a statistician, BAYES RULE\n",
    "\n",
    "What if we **combine** two distributions? Should one be able to hav esuch power?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = Distributions.BayesRule(\n",
    "    [a_simple_distribution, a_more_complicated_distribution]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Work pretty flawlessly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proposals = 50000\n",
    "\n",
    "sampler.sample(\n",
    "    \"posterior_samples.h5\",\n",
    "    posterior,\n",
    "    proposals=proposals,\n",
    "    autotuning=True,  # Cheating, but hey\n",
    "    overwrite_existing_file=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, assess burn-in to be safe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.plot_stepsizes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\n",
    "    \"posterior_samples.h5\",\n",
    "    burn_in=0,  # Change that number in here to something reasonable\n",
    ") as samples:\n",
    "    Visualization.marginal(samples, 0, bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4: Your _own_ inverse problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax  # This package is too cool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making your own class in this package is really easy! There is only one thing missing here still, **the forward model calculation. Write this guy yourself.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarthquakeLocation1D(Distributions._AbstractDistribution):\n",
    "    \"1D earthquake location for 2 events with unknown velocity.\"\n",
    "\n",
    "    dimensions = 3\n",
    "\n",
    "    def __init__(self, observation_1, observation_2, uncertainty):\n",
    "\n",
    "        # Storing the observed data\n",
    "        self.observation_1 = observation_1\n",
    "        self.observation_2 = observation_2\n",
    "        self.uncertainty = uncertainty\n",
    "\n",
    "        # The \"I didnt't like calculus\" approach, choice #1 in Silicon Valley\n",
    "        self.gradient = jax.jit(jax.grad(self.misfit))\n",
    "\n",
    "    def misfit(self, model_vector):\n",
    "        \"\"\"The misfit function. Typically contains a forward model and a measure that\n",
    "        compares synthetics with observations, such as the L2 misfit.\"\"\"\n",
    "\n",
    "        # Deconstruct the vector\n",
    "        medium_velocity = model_vector[0, 0]\n",
    "        distance_event_1 = model_vector[1, 0]\n",
    "        distance_event_2 = model_vector[2, 0]\n",
    "\n",
    "        predicted_arrival_time_event_1 = None  # You can do this, come on!\n",
    "        predicted_arrival_time_event_2 = None  # ------------------------------------------------------<<<\n",
    "\n",
    "        data_residual_1 = self.observation_1 - predicted_arrival_time_event_1\n",
    "        data_residual_2 = self.observation_2 - predicted_arrival_time_event_2\n",
    "\n",
    "        l2_misfit = (\n",
    "            0.5 * (data_residual_1 ** 2 + data_residual_2 ** 2) / (uncertainty ** 2)\n",
    "        )\n",
    "\n",
    "        return l2_misfit\n",
    "\n",
    "    def gradient(model_vector):\n",
    "        \"I didn't do a PhD to derive analytical gradients.\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's 'create' some true data! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# True parameters to find in the inversion:\n",
    "# medium_velocity = 2.75 km/s\n",
    "# distance_event_1 = 55.825 km\n",
    "# distance_event_2 = 10.175 km\n",
    "\n",
    "# Observed arrival times (uncertainty = 1.0 sec)\n",
    "arrival_time_1 = 20.3  #        = 55.825/2.75\n",
    "arrival_time_2 = 3.7  #         = 10.175/2.75\n",
    "uncertainty = 1.0\n",
    "\n",
    "# And wrapping everything up in a likelihood function.\n",
    "eq_likelihood = EarthquakeLocation1D(arrival_time_1, arrival_time_2, uncertainty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we make our starting model be **something really really bad**, just to prove how good my code is (spoiler, it isn't that great)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_starting = np.array([[4.0], [10.0], [10.0]])\n",
    "\n",
    "# Initial misfit and gradient, just to check all the bits and pieces are moving.\n",
    "m = eq_likelihood.misfit(m_starting)\n",
    "g = eq_likelihood.gradient(m_starting)\n",
    "\n",
    "print(m)\n",
    "print(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A finite difference test to make sure our fancy 3rd party software _JAX_ does what it should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_finite_differences(f, x):\n",
    "    eps = 1e-10\n",
    "    g = np.empty_like(x)\n",
    "    for i, ix in enumerate(x):\n",
    "        x_acc = x.copy()\n",
    "        x_acc[i] += eps\n",
    "        g[i] = (f(x_acc) - f(x)) / eps\n",
    "    return g\n",
    "\n",
    "\n",
    "first_finite_differences(eq_likelihood.misfit, m_starting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's pretty cool!\n",
    "\n",
    "Now, on to sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Samplers.RWMH()\n",
    "\n",
    "sampler.sample(\n",
    "    \"samples_eq.h5\",\n",
    "    eq_likelihood,\n",
    "    stepsize=1e-1,\n",
    "    proposals=100000,\n",
    "    online_thinning=10,\n",
    "    initial_model=m_starting,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\"samples_eq.h5\", burn_in=0) as samples:\n",
    "    Visualization.marginal_grid(samples, [0, 1, 2], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a pretty bad result, maybe we should constrain ourselves a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a vector for conveniece\n",
    "ones = np.ones((1, 1))\n",
    "\n",
    "# Prior normal distribution on velocity\n",
    "prior_velocity = Distributions.Normal(ones * 2.65, ones * (0.1 ** 2))\n",
    "\n",
    "# Extremely wide uniform on distance\n",
    "prior_distance_1 = Distributions.Uniform(lower_bounds=ones * 0, upper_bounds=ones * 100)\n",
    "prior_distance_2 = prior_distance_1\n",
    "\n",
    "prior = Distributions.CompositeDistribution(\n",
    "    [prior_velocity, prior_distance_1, prior_distance_2]\n",
    ")\n",
    "\n",
    "print(prior.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining our data and prior to make a posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_posterior = Distributions.BayesRule([prior, eq_likelihood])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Samplers.HMC()\n",
    "\n",
    "sampler.sample(\n",
    "    \"samples_eq_posterior.h5\",\n",
    "    eq_posterior,\n",
    "    stepsize=1e-1,\n",
    "    proposals=1000,\n",
    "    online_thinning=1,\n",
    "    initial_model=m_starting,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\"samples_eq_posterior.h5\", burn_in=0) as samples:\n",
    "    Visualization.marginal_grid(samples, [0, 1, 2], bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using an estimate of the posterior covariance, we can dramaticallyt speed up sampling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = Samplers.RWMH()\n",
    "\n",
    "stepsize = np.array([[0.1], [3.0], [2.5]])\n",
    "\n",
    "sampler.sample(\n",
    "    \"samples_eq_posterior_rwmh.h5\",\n",
    "    eq_posterior,\n",
    "    stepsize=stepsize,\n",
    "    proposals=100000,\n",
    "    online_thinning=10,\n",
    "    initial_model=m_starting,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Samples(\"samples_eq_posterior_rwmh.h5\", burn_in=0) as samples:\n",
    "    Visualization.marginal_grid(samples, [0, 1, 2], bins=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great success!**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
